{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Create New Tenant\n",
        "\n",
        "This chains together a lot of concepts from other notebooks."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pip install azure-mgmt-sql requests msal pyodbc requests_toolbelt"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560751115
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For orgaization purposes I put notbooks in subfolders not the root of the proejct.aad_token\n",
        "#This code adds the root directory of the project to the sys path so we can load class modules from the services folder\n",
        "#I think this only needs to be run once, but including it for completeness.\n",
        "import os, sys\n",
        "projectRoot = os.path.abspath('.')\n",
        "directory = os.path.dirname(projectRoot)\n",
        "if not directory in sys.path: sys.path.append(directory)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560751289
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This leverages the code encapsulated in services/aadservice.py that encapsulates the service principle login\n",
        "#Here we're just getting the credential with out a scope because we'll request different scopes throughout this example\n",
        "from services.aadservice import AadService\n",
        "credential = AadService.get_credential()"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560752098
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 1 - Find Next Tenant Name\n"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This leverages the code encapsulated in services/aadservice.py that encapsulates the service principle login\n",
        "#Retrieving for the Power BI scope here \n",
        "scope = 'https://analysis.windows.net/powerbi/api/.default'\n",
        "aadPBIToken = credential.get_token(scope).token\n",
        "\n",
        "pbiApiHeaders =  {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + aadPBIToken}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560752375
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we're retreiving a list of power bi workspaces\n",
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups'       \n",
        "\n",
        "apiResponse = requests.get(apiUrl, headers=pbiApiHeaders)\n",
        "#error handling for API call\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error retreiving workspace:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    print(json.dumps(apiResponse,indent=2))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560752553
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In this cell we're iterating the list of workspaces to find the max suffix for our \"tenantRoot\" value defined in our constnats.\n",
        "#This helps us name the tenants resources consistently with an ordinal suffix.\n",
        "from services.env import const\n",
        "\n",
        "workspaces = apiResponse[\"value\"]\n",
        "\n",
        "keyPosition = 0\n",
        "keyValue = 0\n",
        "\n",
        "for workspace in workspaces:\n",
        "    nameParts = workspace[\"name\"].split(const.tenantRoot)\n",
        "    #if there was an underscroe in the title, get the suffix of the database name.\n",
        "    if len(nameParts) > 1:\n",
        "        #if the suffix is greater than our max capture it as the new max\n",
        "        if int(nameParts[1]) > keyValue:\n",
        "            keyValue = int(nameParts[1])\n",
        "keyValue = keyValue+1\n",
        "tenantName = f\"{const.tenantRoot}{keyValue}\"\n",
        "\n",
        "print(f\"Next tenant is: {tenantName}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560752842
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 2 - Create Tenant Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#This creates the new pwoer bi workspace with the generated tenant name.  It's important for us to grab the workspace id at this time\n",
        "#we'll need it later.\n",
        "import requests\n",
        "import json\n",
        "from services.env import const\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups?workspaceV2=True'       \n",
        "\n",
        "body = {\"name\":tenantName}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=pbiApiHeaders, data=json.dumps(body))\n",
        "#error handling for create workspace\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error creating workspace:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    workspace = json.loads(apiResponse.text)\n",
        "    workspaceId = workspace[\"id\"]\n",
        "    print(f\"Workspace {workspaceId} created\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560753623
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#By default the API caller will be the only user with permissions on the workspace.  Here we add our global admin user from\n",
        "#the constants definition so we can login to powerbi.com and inspect the workspace.\n",
        "import requests\n",
        "import json\n",
        "from services.env import const\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/users'       \n",
        "\n",
        "body = {\n",
        "  \"emailAddress\": const.globalAdminUser,\n",
        "  \"groupUserAccessRight\": \"Admin\"\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=pbiApiHeaders, data=json.dumps(body))\n",
        "#error handling for adding user\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error creating user:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    print(f\"User {const.globalAdminUser} added\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560754113
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 3:  Create Tenant Capacity"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we're getting a token for the azure management scope so we can create azure resources.\n",
        "scope = 'https://management.azure.com/.default'\n",
        "azureMgmtToken = credential.get_token(scope).token\n",
        "\n",
        "azureApiHeaders =  {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + azureMgmtToken}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560754294
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#And now creating the fabric capacity with the prescribed tenant name, and the list of administrators from the constants file.\n",
        "#The administrators list is important, because only administrators will be able to see the capacity in the Power BI API.\n",
        "import requests\n",
        "import json\n",
        "from services.env import const\n",
        "\n",
        "apiUrl = f'https://management.azure.com/subscriptions/{const.subscriptionId}/resourceGroups/{const.resourceGroup}/providers/Microsoft.Fabric/capacities/{tenantName}?api-version=2022-07-01-preview'       \n",
        "\n",
        "body = { \n",
        "            \"type\": \"Microsoft.Fabric/capacities\",\n",
        "            \"name\": tenantName,\n",
        "            \"location\": \"westus3\",\n",
        "            \"sku\": {\n",
        "                \"name\": \"F2\",\n",
        "                \"tier\": \"Fabric\"\n",
        "            },\n",
        "            \"properties\": {\n",
        "                \"administration\": {\n",
        "                    \"members\": const.administrators\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "apiResponse = requests.put(apiUrl, headers=azureApiHeaders, data=json.dumps(body))\n",
        "\n",
        "#error handling for create capacity\n",
        "if apiResponse.status_code != 201 and apiResponse.status_code != 200:\n",
        "    description = f'Error creating capacity:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    print(f\"Capacity '{tenantName}' created\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560757195
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 4:  Add Capacity to Workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we're looking for the capacity we just created in the Power BI API, matching it by display name to get its id.\n",
        "import requests\n",
        "import json\n",
        "\n",
        "capacityId = \"blank\"\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/capacities'      \n",
        "\n",
        "apiResponse = requests.get(apiUrl, headers=pbiApiHeaders)\n",
        "#error handling for createTemporaryUplodadLocation\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error creating workspace:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    capacities = apiResponse[\"value\"]\n",
        "    for capacity in capacities:\n",
        "        if capacity[\"displayName\"] == tenantName:\n",
        "            capacityId = capacity[\"id\"]\n",
        "\n",
        "    print(f\"The capacity {tenantName} has id {capacityId}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560761095
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now that we know the capacity id and the workspace id, we can assign the capacity to the workspace.\n",
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/AssignToCapacity'      \n",
        "\n",
        "body = {'capacityId': capacityId}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=pbiApiHeaders, data=json.dumps(body))\n",
        "\n",
        "#error handling for capacity assignment.\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error assigning capacity:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    print(f\"Capacity {capacityId} assigned to workspace {workspaceId}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560762071
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 5: Create Tenant Service Principal"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now we get a token for the graph api because we need to work with entra users.\n",
        "scope = 'https://graph.microsoft.com/.default'\n",
        "\n",
        "#with the credential object, get the token for the azure management scope.\n",
        "graphApiToken = credential.get_token(scope).token\n",
        "graphApiHeaders =  {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + graphApiToken}"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560762243
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#First we create a new application specific to this tenant.  This is a security best practice.\n",
        "import requests\n",
        "import json\n",
        "\n",
        "#appId = str(uuid.uuid4())\n",
        "apiUrl = f'https://graph.microsoft.com/v1.0/applications'       \n",
        "\n",
        "body = {\n",
        "    \"displayName\": tenantName,\n",
        "    \"passwordCredentials\":[\n",
        "        {\n",
        "            \"displayName\": \"auth secret\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=graphApiHeaders, data=json.dumps(body))\n",
        "\n",
        "#error handling for create capacity\n",
        "if apiResponse.status_code != 201 and apiResponse.status_code != 200:\n",
        "    description = f'Error creating capacity:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    print(json.dumps(apiResponse,indent=2))"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560762423
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Since we creted an application with an auth secret, we need to persist that secret in keyvault so we can use it later.\n",
        "from services.secretservice import SecretService\n",
        "from services.env import const\n",
        "\n",
        "#Grab the app id and client secret for the created application.\n",
        "appId = apiResponse[\"appId\"]\n",
        "secrets = apiResponse[\"passwordCredentials\"]\n",
        "secret = secrets[0]\n",
        "secretText = secret[\"secretText\"]\n",
        "\n",
        "#SecretService.get_secret_byname(keyVault,\"foo\")\n",
        "appIdKey = f'{tenantName}Id'\n",
        "appSecretKey = f'{tenantName}Secret'\n",
        "\n",
        "SecretService.store_secret_byname(const.keyVault, appIdKey, appId)\n",
        "SecretService.store_secret_byname(const.keyVault, appSecretKey, secretText)"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560764230
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Now that the application is created, we need to convert it to a service principal.\n",
        "import requests\n",
        "import json\n",
        "\n",
        "#appId = str(uuid.uuid4())\n",
        "apiUrl = f'https://graph.microsoft.com/v1.0/servicePrincipals'       \n",
        "\n",
        "body = {\n",
        "  \"appId\": appId\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=graphApiHeaders, data=json.dumps(body))\n",
        "\n",
        "#error handling for create capacity\n",
        "if apiResponse.status_code != 201 and apiResponse.status_code != 200:\n",
        "    description = f'Error creating capacity:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    print(f\"Application {appId} converted to Service Principal\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560764419
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 6:  Create Azure SQL Database\n",
        "\n",
        "Extensive details on what this script does are covered in CreateSQLDB.ipynb.  In this step we're creating a new database as a copy of an existing \"template\" database.   While there are multiple ways to create an empty database with a specific schema this is the fewest steps.  Other options include:\n",
        "\n",
        "1. Create a blank database and deploy a schema from a script.\n",
        "1. Create the database as a restore from a backup file.\n",
        "\n",
        "Another advantage of this approach is if there are any users that need to have admin access to all databases this user grant, or static data that needs to be included, it can all exist in the database already and will be there already after the copy."
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In our example we have a blank \"template\" database that has the schema defined but is essentially empty.\n",
        "#Here we create a new database for the tenant as a clone of the existing template databsae.\n",
        "from azure.mgmt.sql import SqlManagementClient\n",
        "import json\n",
        "from services.env import const\n",
        "\n",
        "try:\n",
        "    #\n",
        "    sqlClient = SqlManagementClient(credential=credential, subscription_id=const.subscriptionId)\n",
        "    \n",
        "    # Create database\n",
        "    database = sqlClient.databases.begin_create_or_update(\n",
        "        const.resourceGroup,\n",
        "        const.serverName,\n",
        "        tenantName,\n",
        "        {\n",
        "            \"location\": const.location,\n",
        "            \"sku\": {\n",
        "                \"name\": \"S0\",\n",
        "                \"tier\": \"Standard\"\n",
        "            },\n",
        "            \"properties\": {\n",
        "                \"createMode\": \"Copy\",\n",
        "                \"sourceDatabaseId\": f\"/subscriptions/{const.subscriptionId}/resourceGroups/{const.resourceGroup}/providers/Microsoft.Sql/servers/{const.serverName}/databases/template\"\n",
        "            }\n",
        "        }\n",
        "        ).result()\n",
        "\n",
        "    print(f\"Database {tenantName} created\")\n",
        "except KeyError:\n",
        "    print(f\"Database {tenantName} create failed\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560873107
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now that we've created a database on the precreated server, we want to do some post configuration on that database.  The server's admin account is running as a service principal.  In order to let us connect to that datbabase directly we need to add an additional Entra user to the database.  I'll do this using and ODBC connection and a couple SQL commands to create a local database user that corresponds to an Entra user and also grant that user owner permissions on the database.\n",
        "\n",
        "This is an example of where you'd likely create a tenant specific user for the database and grant that user access.\n",
        "\n",
        "Supporting docs:\n",
        "\n",
        "1. How to install SQL ODBC drivers on Linux:  https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline\n",
        "2. How to connect to a database with pyodbc drivers and a service principal login:  https://learn.microsoft.com/en-us/azure/azure-sql/database/azure-sql-passwordless-migration-python?view=azuresql&tabs=sign-in-azure-cli%2Cazure-portal-create%2Cazure-portal-assign%2Capp-service-identity"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we connect to the sql database with the primary service principal, and exectue some commands to grant the app service principal\n",
        "#reader access.\n",
        "import struct\n",
        "import pyodbc\n",
        "import json\n",
        "from services.secretservice import SecretService\n",
        "from services.env import const\n",
        "\n",
        "serverFqdn = f'{const.serverName}.database.windows.net'\n",
        "driver = '{ODBC Driver 18 for SQL Server}'\n",
        "\n",
        "#Get a credential for database access.\n",
        "tokenBytes = credential.get_token(\"https://database.windows.net/.default\").token.encode(\"UTF-16-LE\")\n",
        "token_struct = struct.pack(f'<I{len(tokenBytes)}s', len(tokenBytes), tokenBytes)\n",
        "SQL_COPT_SS_ACCESS_TOKEN = 1256\n",
        "\n",
        "#open the connection\n",
        "conn_str = f'DRIVER={driver};SERVER={serverFqdn};DATABASE={tenantName};'\n",
        "conn = pyodbc.connect(conn_str,attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\n",
        "\n",
        "#Update our \"WhoAmI\" table so we have a basic table to prove our reports are connected to another database\n",
        "sql = f\"TRUNCATE TABLE WhoAmI\\n\\rINSERT INTO WhoAmI VALUES ('{tenantName}')\"\n",
        "conn.execute(sql)\n",
        "sql = f\"CREATE USER [{tenantName}] FROM EXTERNAL PROVIDER;\"\n",
        "conn.execute(sql)\n",
        "sql = f\"ALTER ROLE db_datareader ADD MEMBER [{tenantName}];\"\n",
        "conn.execute(sql)\n",
        "\n",
        "#This is important, the connection doesn't auto commit\n",
        "conn.commit()\n",
        "\n",
        "print(f\"Application {appId} granted data reader permissions on database {tenantName}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560875542
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 7 - Deploy Power BI Model to workspace"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#For our template database we have a prebuilt pbix model that has parameters for servername and database name.\n",
        "#Here we deploy this pbix file to the new tenant workspace\n",
        "import requests\n",
        "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
        "\n",
        "fileLocation = '../files/Template.pbix'\n",
        "\n",
        "url = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/imports?datasetDisplayName={tenantName}'\n",
        "headers = {\n",
        "    'Content-Type': 'multipart/form-data',\n",
        "    'authorization': 'Bearer ' + aadPBIToken\n",
        "}\n",
        "\n",
        "# you need this dictionary to convert a binary file into form-data format\n",
        "# None here means we skip the filename and file content is important \n",
        "files = {'value': (None, open(fileLocation, 'rb'), 'multipart/form-data')}\n",
        "\n",
        "mp_encoder = MultipartEncoder(fields=files)\n",
        "\n",
        "r = requests.post(\n",
        "    url=url,\n",
        "    data=mp_encoder,  # The MultipartEncoder is posted as data, don't use files=...!\n",
        "    # The MultipartEncoder provides the content-type header with the boundary:\n",
        "    headers=headers\n",
        ")\n",
        "\n",
        "print(f\"File {fileLocation} deployed to workspace {workspaceId}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560878405
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 8 - Change Dataset Connection"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#/myorg/groups/{workspace_id}/datasets\n",
        "#This retreives a list of datasets in the given workspace, notice the response value is wrapped in an array []\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "#Injecting a wait to make sure Power BI has had time to enumerate datasets in the uploaded model.\n",
        "time.sleep(15)\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets'       \n",
        "\n",
        "\n",
        "# Generate Embed token for multiple workspaces, datasets, and reports. Refer https://aka.ms/MultiResourceEmbedToken\n",
        "apiResponse = requests.get(apiUrl, headers=pbiApiHeaders)\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error while retrieving datasets:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    datasets = apiResponse[\"value\"]\n",
        "    dataset = datasets[0]\n",
        "    datasetId = dataset[\"id\"]\n",
        "\n",
        "    print(f\"Deployed model has datasetId: {datasetId}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560894072
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we're setting values for the dataset paremeters so on refres the model connects to the correct database.\n",
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/Default.UpdateParameters'       \n",
        "\n",
        "body = {\n",
        "    \"updateDetails\": [\n",
        "        {\n",
        "            \"name\": \"server\",\n",
        "            \"newValue\": serverFqdn\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"database\",\n",
        "            \"newValue\": tenantName\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=pbiApiHeaders, data=json.dumps(body))\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error while updating dataset parameters:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    print(f\"Dataset {datasetId} parameters changed successfully\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560896132
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/datasources'       \n",
        "\n",
        "apiResponse = requests.get(apiUrl, headers=pbiApiHeaders)\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error while retrieving datasets:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    datasources = apiResponse[\"value\"]\n",
        "    datasource = datasources[0]\n",
        "    datasourceId = datasource[\"datasourceId\"]\n",
        "    gatewayId = datasource[\"gatewayId\"]\n",
        "    print(f\"Dataset {datasetId} has datasource {datasourceId} on gateway {gatewayId}\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560896370
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Here we're getting a sql auth token and setting the credentials on the datasource.\n",
        "#\n",
        "#Note:  \n",
        "#The API doesn't presently support passing an oAuth2 refresh token.  As such this token will be short lived (1 hour).\n",
        "#in order to overcome this limitation the only present option with the API is using sql authentication.\n",
        "#this will be addressed in the future with an updated API in fabric.\n",
        "import requests\n",
        "import json\n",
        "from services.aadservice import AadService\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/gateways/{gatewayId}/datasources/{datasourceId}'       \n",
        "\n",
        "#We need a SQL Auth token for the new tenant login we created\n",
        "credential = AadService.get_tenant_credential(tenantName)\n",
        "aadSQLToken = credential.get_token(\"https://database.windows.net/.default\").token\n",
        "\n",
        "serialized_credentials = '{\\'credentialData\\':[{\\'name\\':\\'accessToken\\',\\'value\\':\\'' + aadSQLToken + '\\'}]}'\n",
        "\n",
        "body = {\n",
        "    \"credentialDetails\": {\n",
        "        \"credentialType\": \"OAuth2\",\n",
        "        \"credentials\": serialized_credentials,\n",
        "        \"encryptedConnection\": \"NotEncrypted\",\n",
        "        \"encryptionAlgorithm\": \"None\",\n",
        "        \"privacyLevel\": \"None\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "apiResponse = requests.patch(apiUrl, data=json.dumps(body), headers=pbiApiHeaders)\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error while retrieving datasets:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    print(f\"Updated credentials on datasource {datasourceId}\")\n"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560898331
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Part 9 - Refresh Model"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Finally now that we have an auth token applied to the connection, we can kick off a model refresh\n",
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/refreshes'       \n",
        "\n",
        "body = {\n",
        "  \"notifyOption\": \"NoNotification\",\n",
        "  \"retryCount\": 3\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, data=json.dumps(body), headers=pbiApiHeaders)\n",
        "if apiResponse.status_code != 202:\n",
        "    description = f'Error while retrieving datasets:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    print(f\"Refresh on dataset {datasetId} in workspace {workspaceId} initiated Successfully\")"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1716560899066
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "name": "python38-azureml",
      "language": "python",
      "display_name": "Python 3.8 - AzureML"
    },
    "language_info": {
      "name": "python",
      "version": "3.8.5",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}