{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "# Create New Tenant\n",
        "\n",
        "This chains together a lot of concepts from other notebooks."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267877483
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "pip install azure-mgmt-sql requests msal pyodbc requests_toolbelt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#For orgaization purposes I put notbooks in subfolders not the root of the proejct.aad_token\n",
        "#This code adds the root directory of the project to the sys path so we can load class modules from the services folder\n",
        "#I think this only needs to be run once, but including it for completeness.\n",
        "import os, sys\n",
        "projectRoot = os.path.abspath('.')\n",
        "directory = os.path.dirname(projectRoot)\n",
        "if not directory in sys.path: sys.path.append(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267877882
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "resourceGroup = \"cgmpbie\"\n",
        "subscriptionId = \"7258b7d4-3429-4998-815b-8cd6954b7ef9\"\n",
        "serverName = \"cgmpbiesqlserver\"\n",
        "tenantRoot = \"cgmpbietenant\"\n",
        "location = \"westus2\"\n",
        "\n",
        "#We use this user so that we can examine what we've created after the fact.\n",
        "globalAdminUser = \"chmitch@microsoftanalytics.info\"\n",
        "\n",
        "#We always add these two users, one is our service principal.  This allows us to manipulate the workspace after it's created\n",
        "#the other is the app id of our service principal.  This ensures we can assign capacities to worksapces after they are created.\n",
        "administrators = [globalAdminUser,'6709b293-4789-477f-aee2-607b7139e63c']\n",
        "\n",
        "keyVault = \"cgmmlservicevault\"\n",
        "\n",
        "#Add another Admin to the database for convenience so you can connect to the database in Azure Data Studio or Query Editor.\n",
        "secondaryAdmin = \"chmitch@microsoftanalyitcs.info\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267878683
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#This leverages the code encapsulated in services/aadservice.py that encapsulates the service principle login\n",
        "from services.aadservice import AadService\n",
        "credential = AadService.get_credential()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 1 - Find Next Tenant Name\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267878962
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#This leverages the code encapsulated in services/aadservice.py that encapsulates the service principle login\n",
        "scope = 'https://analysis.windows.net/powerbi/api/.default'\n",
        "aadPBIToken = credential.get_token(scope).token\n",
        "\n",
        "pbiApiHeaders =  {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + aadPBIToken}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267879391
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups'       \n",
        "\n",
        "apiResponse = requests.get(apiUrl, headers=pbiApiHeaders)\n",
        "#error handling for API call\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error retreiving workspace:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    print(json.dumps(apiResponse,indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267879578
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "workspaces = apiResponse[\"value\"]\n",
        "\n",
        "keyPosition = 0\n",
        "keyValue = 0\n",
        "\n",
        "for workspace in workspaces:\n",
        "    nameParts = workspace[\"name\"].split(tenantRoot)\n",
        "    #if there was an underscroe in the title, get the suffix of the database name.\n",
        "    if len(nameParts) > 1:\n",
        "        #if the suffix is greater than our max capture it as the new max\n",
        "        if int(nameParts[1]) > keyValue:\n",
        "            keyValue = int(nameParts[1])\n",
        "keyValue = keyValue+1\n",
        "tenantName = f\"{tenantRoot}{keyValue}\"\n",
        "\n",
        "print(f\"Next tenant is: {tenantName}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 2 - Create Tenant Workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267880331
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups?workspaceV2=True'       \n",
        "\n",
        "body = {\"name\":tenantName}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=pbiApiHeaders, data=json.dumps(body))\n",
        "#error handling for createTemporaryUplodadLocation\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error creating workspace:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    workspace = json.loads(apiResponse.text)\n",
        "    workspaceId = workspace[\"id\"]\n",
        "    print(f\"Workspace {workspaceId} created\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267880652
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/users'       \n",
        "\n",
        "body = {\n",
        "  \"emailAddress\": globalAdminUser,\n",
        "  \"groupUserAccessRight\": \"Admin\"\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=pbiApiHeaders, data=json.dumps(body))\n",
        "#error handling for adding user\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error creating user:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    print(f\"User {globalAdminUser} added\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 3:  Create Tenant Capacity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267880908
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "scope = 'https://management.azure.com/.default'\n",
        "azureMgmtToken = credential.get_token(scope).token\n",
        "\n",
        "azureApiHeaders =  {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + azureMgmtToken}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267883734
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://management.azure.com/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Fabric/capacities/{tenantName}?api-version=2022-07-01-preview'       \n",
        "\n",
        "body = { \n",
        "            \"type\": \"Microsoft.Fabric/capacities\",\n",
        "            \"name\": tenantName,\n",
        "            \"location\": \"westus3\",\n",
        "            \"sku\": {\n",
        "                \"name\": \"F2\",\n",
        "                \"tier\": \"Fabric\"\n",
        "            },\n",
        "            \"properties\": {\n",
        "                \"administration\": {\n",
        "                    \"members\": administrators\n",
        "                }\n",
        "            }\n",
        "        }\n",
        "\n",
        "apiResponse = requests.put(apiUrl, headers=azureApiHeaders, data=json.dumps(body))\n",
        "\n",
        "#error handling for create capacity\n",
        "if apiResponse.status_code != 201 and apiResponse.status_code != 200:\n",
        "    description = f'Error creating capacity:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    print(f\"Capacity '{tenantName}' created\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 4:  Add Capacity to Workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267888490
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "capacityId = \"blank\"\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/capacities'      \n",
        "\n",
        "apiResponse = requests.get(apiUrl, headers=pbiApiHeaders)\n",
        "#error handling for createTemporaryUplodadLocation\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error creating workspace:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    capacities = apiResponse[\"value\"]\n",
        "    for capacity in capacities:\n",
        "        if capacity[\"displayName\"] == tenantName:\n",
        "            capacityId = capacity[\"id\"]\n",
        "\n",
        "    print(f\"The capacity {tenantName} has id {capacityId}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267888888
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "api_url = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/AssignToCapacity'      \n",
        "\n",
        "body = {'capacityId': capacityId}\n",
        "\n",
        "api_response = requests.post(api_url, headers=pbiApiHeaders, data=json.dumps(body))\n",
        "\n",
        "#error handling for capacity assignment.\n",
        "if api_response.status_code != 200:\n",
        "    description = f'Error assigning capacity:\\n  -Status Code:\\t{api_response.status_code}\\n  -Reason:\\t{api_response.reason}\\n  -RequestId:\\t{api_response.headers.get(\"RequestId\")}\\n  -Text:\\t{api_response.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    print(f\"Capacity {capacityId} assigned to workspace {workspaceId}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 5: Create Tenant Service Principal"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267889164
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "scope = 'https://graph.microsoft.com/.default'\n",
        "\n",
        "#with the credential object, get the token for the azure management scope.\n",
        "graphApiToken = credential.get_token(scope).token\n",
        "graphApiHeaders =  {'Content-Type': 'application/json', 'Authorization': 'Bearer ' + graphApiToken}"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267889503
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "#appId = str(uuid.uuid4())\n",
        "apiUrl = f'https://graph.microsoft.com/v1.0/applications'       \n",
        "\n",
        "body = {\n",
        "    \"displayName\": tenantName,\n",
        "    \"passwordCredentials\":[\n",
        "        {\n",
        "            \"displayName\": \"auth secret\"\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=graphApiHeaders, data=json.dumps(body))\n",
        "\n",
        "#error handling for create capacity\n",
        "if apiResponse.status_code != 201 and apiResponse.status_code != 200:\n",
        "    description = f'Error creating capacity:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    print(json.dumps(apiResponse,indent=2))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267890375
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from services.secretservice import SecretService\n",
        "\n",
        "#Grab the app id and client secret for the created application.\n",
        "appId = apiResponse[\"appId\"]\n",
        "secrets = apiResponse[\"passwordCredentials\"]\n",
        "secret = secrets[0]\n",
        "secretText = secret[\"secretText\"]\n",
        "\n",
        "#SecretService.get_secret_byname(keyVault,\"foo\")\n",
        "appIdKey = f'{tenantName}Id'\n",
        "appSecretKey = f'{tenantName}Secret'\n",
        "\n",
        "SecretService.store_secret_byname(keyVault, appIdKey, appId)\n",
        "SecretService.store_secret_byname(keyVault, appSecretKey, secretText)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267890721
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "#appId = str(uuid.uuid4())\n",
        "apiUrl = f'https://graph.microsoft.com/v1.0/servicePrincipals'       \n",
        "\n",
        "body = {\n",
        "  \"appId\": appId\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, headers=graphApiHeaders, data=json.dumps(body))\n",
        "\n",
        "#error handling for create capacity\n",
        "if apiResponse.status_code != 201 and apiResponse.status_code != 200:\n",
        "    description = f'Error creating capacity:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "else:\n",
        "    print(f\"Application {appId} converted to Service Principal\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 6:  Create Azure SQL Database\n",
        "\n",
        "Extensive details on what this script does are covered in CreateSQLDB.ipynb.  In this step we're creating a new database as a copy of an existing \"template\" database.   While there are multiple ways to create an empty database with a specific schema this is the fewest steps.  Other options include:\n",
        "\n",
        "1. Create a blank database and deploy a schema from a script.\n",
        "1. Create the database as a restore from a backup file.\n",
        "\n",
        "Another advantage of this approach is if there are any users that need to have admin access to all databases this user grant, or static data that needs to be included, it can all exist in the database already and will be there already after the copy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715267999380
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from azure.mgmt.sql import SqlManagementClient\n",
        "import json\n",
        "\n",
        "try:\n",
        "    #\n",
        "    sqlClient = SqlManagementClient(credential=credential, subscription_id=subscriptionId)\n",
        "    \n",
        "    # Create database\n",
        "    database = sqlClient.databases.begin_create_or_update(\n",
        "        resourceGroup,\n",
        "        serverName,\n",
        "        tenantName,\n",
        "        {\n",
        "            \"location\": location,\n",
        "            \"sku\": {\n",
        "                \"name\": \"S0\",\n",
        "                \"tier\": \"Standard\"\n",
        "            },\n",
        "            \"properties\": {\n",
        "                \"createMode\": \"Copy\",\n",
        "                \"sourceDatabaseId\": f\"/subscriptions/{subscriptionId}/resourceGroups/{resourceGroup}/providers/Microsoft.Sql/servers/{serverName}/databases/template\"\n",
        "            }\n",
        "        }\n",
        "        ).result()\n",
        "\n",
        "    print(f\"Database {tenantName} created\")\n",
        "except KeyError:\n",
        "    print(f\"Database {tenantName} create failed\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "Now that we've created a database on the precreated server, we want to do some post configuration on that database.  The server's admin account is running as a service principal.  In order to let us connect to that datbabase directly we need to add an additional Entra user to the database.  I'll do this using and ODBC connection and a couple SQL commands to create a local database user that corresponds to an Entra user and also grant that user owner permissions on the database.\n",
        "\n",
        "This is an example of where you'd likely create a tenant specific user for the database and grant that user access.\n",
        "\n",
        "Supporting docs:\n",
        "\n",
        "1. How to install SQL ODBC drivers on Linux:  https://learn.microsoft.com/en-us/sql/connect/odbc/linux-mac/installing-the-microsoft-odbc-driver-for-sql-server?view=sql-server-ver16&tabs=ubuntu18-install%2Calpine17-install%2Cdebian8-install%2Credhat7-13-install%2Crhel7-offline\n",
        "2. How to connect to a database with pyodbc drivers and a service principal login:  https://learn.microsoft.com/en-us/azure/azure-sql/database/azure-sql-passwordless-migration-python?view=azuresql&tabs=sign-in-azure-cli%2Cazure-portal-create%2Cazure-portal-assign%2Capp-service-identity"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715268001755
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import struct\n",
        "import pyodbc\n",
        "import json\n",
        "from services.secretservice import SecretService\n",
        "\n",
        "serverFqdn = f'{serverName}.database.windows.net'\n",
        "driver = '{ODBC Driver 18 for SQL Server}'\n",
        "\n",
        "#Get a credential for database access.\n",
        "tokenBytes = credential.get_token(\"https://database.windows.net/.default\").token.encode(\"UTF-16-LE\")\n",
        "token_struct = struct.pack(f'<I{len(tokenBytes)}s', len(tokenBytes), tokenBytes)\n",
        "SQL_COPT_SS_ACCESS_TOKEN = 1256\n",
        "\n",
        "#open the connection\n",
        "conn_str = f'DRIVER={driver};SERVER={serverFqdn};DATABASE={tenantName};'\n",
        "conn = pyodbc.connect(conn_str,attrs_before={SQL_COPT_SS_ACCESS_TOKEN: token_struct})\n",
        "\n",
        "#Update our \"WhoAmI\" table so we have a basic table to prove our reports are connected to another database\n",
        "sql = f\"TRUNCATE TABLE WhoAmI\\n\\rINSERT INTO WhoAmI VALUES ('{tenantName}')\"\n",
        "conn.execute(sql)\n",
        "sql = f\"CREATE USER [{tenantName}] FROM EXTERNAL PROVIDER;\"\n",
        "conn.execute(sql)\n",
        "sql = f\"ALTER ROLE db_datareader ADD MEMBER [{tenantName}];\"\n",
        "conn.execute(sql)\n",
        "\n",
        "#This is important, the connection doesn't auto commit\n",
        "conn.commit()\n",
        "\n",
        "print(f\"Application {appId} granted data reader permissions on database {tenantName}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 7 - Deploy Power BI Model to workspace"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715268005342
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
        "\n",
        "fileLocation = 'files/Template.pbix'\n",
        "\n",
        "url = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/imports?datasetDisplayName={tenantName}'\n",
        "headers = {\n",
        "    'Content-Type': 'multipart/form-data',\n",
        "    'authorization': 'Bearer ' + aadPBIToken\n",
        "}\n",
        "\n",
        "# you need this dictionary to convert a binary file into form-data format\n",
        "# None here means we skip the filename and file content is important \n",
        "files = {'value': (None, open(fileLocation, 'rb'), 'multipart/form-data')}\n",
        "\n",
        "mp_encoder = MultipartEncoder(fields=files)\n",
        "\n",
        "r = requests.post(\n",
        "    url=url,\n",
        "    data=mp_encoder,  # The MultipartEncoder is posted as data, don't use files=...!\n",
        "    # The MultipartEncoder provides the content-type header with the boundary:\n",
        "    headers=headers\n",
        ")\n",
        "\n",
        "print(f\"File {fileLocation} deployed to workspace {workspaceId}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 8 - Change Dataset Connection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715268020420
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#/myorg/groups/{workspace_id}/datasets\n",
        "#This retreives a list of datasets in the given workspace, notice the response value is wrapped in an array []\n",
        "import requests\n",
        "import json\n",
        "import time\n",
        "\n",
        "#Injecting a wait to make sure Power BI has had time to enumerate datasets in the uploaded model.\n",
        "time.sleep(15)\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets'       \n",
        "\n",
        "\n",
        "# Generate Embed token for multiple workspaces, datasets, and reports. Refer https://aka.ms/MultiResourceEmbedToken\n",
        "apiResponse = requests.get(apiUrl, headers=pbiApiHeaders)\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error while retrieving datasets:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    datasets = apiResponse[\"value\"]\n",
        "    dataset = datasets[0]\n",
        "    datasetId = dataset[\"id\"]\n",
        "\n",
        "    print(f\"Deployed model has datasetId: {datasetId}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715268022684
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/Default.UpdateParameters'       \n",
        "\n",
        "body = {\n",
        "    \"updateDetails\": [\n",
        "        {\n",
        "            \"name\": \"server\",\n",
        "            \"newValue\": serverFqdn\n",
        "        },\n",
        "        {\n",
        "            \"name\": \"database\",\n",
        "            \"newValue\": tenantName\n",
        "        }\n",
        "    ]\n",
        "}\n",
        "\n",
        "# Generate Embed token for multiple workspaces, datasets, and reports. Refer https://aka.ms/MultiResourceEmbedToken\n",
        "apiResponse = requests.post(apiUrl, headers=pbiApiHeaders, data=json.dumps(body))\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error while updating dataset parameters:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    print(f\"Dataset {datasetId} parameters changed successfully\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715268022963
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/datasources'       \n",
        "\n",
        "# Generate Embed token for multiple workspaces, datasets, and reports. Refer https://aka.ms/MultiResourceEmbedToken\n",
        "apiResponse = requests.get(apiUrl, headers=pbiApiHeaders)\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error while retrieving datasets:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    apiResponse = json.loads(apiResponse.text)\n",
        "    datasources = apiResponse[\"value\"]\n",
        "    datasource = datasources[0]\n",
        "    datasourceId = datasource[\"datasourceId\"]\n",
        "    gatewayId = datasource[\"gatewayId\"]\n",
        "    print(f\"Dataset {datasetId} has datasource {datasourceId} on gateway {gatewayId}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715268029392
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "from services.aadservice import AadService\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/gateways/{gatewayId}/datasources/{datasourceId}'       \n",
        "\n",
        "#We need a SQL Auth token for the new tenant login we created\n",
        "credential = AadService.get_tenant_credential(tenantName)\n",
        "aadSQLToken = credential.get_token(\"https://database.windows.net/.default\").token\n",
        "\n",
        "serialized_credentials = '{\\'credentialData\\':[{\\'name\\':\\'accessToken\\',\\'value\\':\\'' + aadSQLToken + '\\'}]}'\n",
        "\n",
        "body = {\n",
        "    \"credentialDetails\": {\n",
        "        \"credentialType\": \"OAuth2\",\n",
        "        \"credentials\": serialized_credentials,\n",
        "        \"encryptedConnection\": \"NotEncrypted\",\n",
        "        \"encryptionAlgorithm\": \"None\",\n",
        "        \"privacyLevel\": \"None\"\n",
        "    }\n",
        "}\n",
        "\n",
        "\n",
        "apiResponse = requests.patch(apiUrl, data=json.dumps(body), headers=pbiApiHeaders)\n",
        "if apiResponse.status_code != 200:\n",
        "    description = f'Error while retrieving datasets:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    print(f\"Updated credentials on datasource {datasourceId}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Part 9 - Refresh Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715268029651
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "\n",
        "apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/datasets/{datasetId}/refreshes'       \n",
        "\n",
        "body = {\n",
        "  \"notifyOption\": \"NoNotification\",\n",
        "  \"retryCount\": 3\n",
        "}\n",
        "\n",
        "apiResponse = requests.post(apiUrl, data=json.dumps(body), headers=pbiApiHeaders)\n",
        "if apiResponse.status_code != 202:\n",
        "    description = f'Error while retrieving datasets:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "    print(description)\n",
        "    #print(api_response.status_code, description=description)\n",
        "else:\n",
        "    print(f\"Refresh on dataset {datasetId} in workspace {workspaceId} initiated Successfully\")"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python38-azureml"
    },
    "kernelspec": {
      "display_name": "Python 3.8 - AzureML",
      "language": "python",
      "name": "python38-azureml"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
