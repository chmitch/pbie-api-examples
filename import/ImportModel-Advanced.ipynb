{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "source": [
        "## Post Import in Group\n",
        "\n",
        "This demonstrates the process of deploying a new Power BI Model as a PBIX file to a Power BI Workspace.  In this project we've provided two sample PBIX files to illustrate these concepts:\n",
        "- files/AdventureWorks.pbix - this is a fairly small model built on the AdventureWorksDW database\n",
        "- files/NYCYellow.pbix - this is a large mode that is over 1GB used to illustrate the asynch process of loading large models via a temporary blob location.  Note that since this file exceeds 1GB it can only be hosted in a workspace with a premium capacity.\n",
        "\n",
        "The general flow of this process is:\n",
        "1. Authenticate the Service Principal.\n",
        "1. Open the local file to determine its size.\n",
        "1. If the file is less than 1GB, read the file as a binary multi-part encoded stream, and call the Imports API for the workspace.\n",
        "1. If the file is larger than 1GB, call the Imports api to generate a temporary upload location, use the blob API to upload the file, and call the Imports API passing in the path to the temporary blob location.\n",
        "\n",
        "The documentation for the relevant APIs can be found here:\n",
        "- https://learn.microsoft.com/en-us/rest/api/power-bi/imports/create-temporary-upload-location-in-group\n",
        "- https://learn.microsoft.com/en-us/rest/api/power-bi/imports/post-import-in-group"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715086443301
        }
      },
      "outputs": [],
      "source": [
        "pip install requests msal jsons azure-storage-blob requests_toolbelt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#For orgaization purposes I put notbooks in subfolders not the root of the proejct.aad_token\n",
        "#This code adds the root directory of the project to the sys path so we can load class modules from the services folder\n",
        "#I think this only needs to be run once, but including it for completeness.\n",
        "import os, sys\n",
        "projectRoot = os.path.abspath('.')\n",
        "directory = os.path.dirname(projectRoot)\n",
        "if not directory in sys.path: sys.path.append(directory)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715086445037
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "workspaceId=\"16453fea-cb0f-4ef4-b1b2-bede9d3b92be\"\n",
        "displayName=\"AdventureWorks.pbix\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715086444871
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "#This leverages the code encapsulated in services/aadservice.py that encapsulates the service principle login\n",
        "from services.aadservice import AadService\n",
        "aadToken = AadService.get_access_token()\n",
        "\n",
        "#we don't prebuild the header like in other examples becuase the reqeusts have different content types"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715086445180
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "from os import path\n",
        "#file_location = 'files/AdventureWorks.pbix'\n",
        "fileLocation = f'files/{displayName}'\n",
        "fileSize = path.getsize(fileLocation)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715086449177
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "from requests_toolbelt.multipart.encoder import MultipartEncoder\n",
        "\n",
        "#This demonstrates loading files under 1GB\n",
        "if fileSize < 1073741824:\n",
        "    print(\"File is less than 1GB this cell is loading the file as form data\")\n",
        "\n",
        "    url = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/imports?datasetDisplayName={displayName}'\n",
        "    headers = {\n",
        "        'Content-Type': 'multipart/form-data',\n",
        "        'authorization': 'Bearer ' + aadToken\n",
        "    }\n",
        "\n",
        "    # you need this dictionary to convert a binary file into form-data format\n",
        "    # None here means we skip the filename and file content is important \n",
        "    files = {'value': (None, open(fileLocation, 'rb'), 'multipart/form-data')}\n",
        "\n",
        "    mp_encoder = MultipartEncoder(fields=files)\n",
        "    print(mp_encoder)\n",
        "    r = requests.post(\n",
        "        url=url,\n",
        "        data=mp_encoder,  # The MultipartEncoder is posted as data, don't use files=...!\n",
        "        # The MultipartEncoder provides the content-type header with the boundary:\n",
        "        headers=headers\n",
        "    )\n",
        "else:\n",
        "    print(\"File is larger than 1GB this cell did nothing\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "gather": {
          "logged": 1715086449317
        },
        "jupyter": {
          "outputs_hidden": false,
          "source_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      },
      "outputs": [],
      "source": [
        "import requests\n",
        "import json\n",
        "from azure.storage.blob import BlobClient\n",
        "\n",
        "#This demonstrates loading files under 1GB\n",
        "if fileSize >= 1073741824:\n",
        "    tempUrl = \"\"\n",
        "\n",
        "    #Part 1:  Request a temporary blob location from the API.\n",
        "    apiUrl = f'https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/imports/createTemporaryUploadLocation'\n",
        "    headers =  {\n",
        "        'Content-Type': 'application/json',\n",
        "        'Authorization': 'Bearer ' + aadToken\n",
        "    } \n",
        "\n",
        "    apiResponse = requests.post(apiUrl, headers=headers)\n",
        "    #error handling for createTemporaryUplodadLocation\n",
        "    if apiResponse.status_code != 200:\n",
        "        description = f'Error requesting temp location:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{api_response.headers.get(\"RequestId\")}\\n  -Text:\\t{api_response.text}'\n",
        "        print(description)\n",
        "    else:\n",
        "        api_response = json.loads(apiResponse.text)\n",
        "        tempUrl = api_response['url']\n",
        "\n",
        "    #Part 2:  Now that we have the temporary location, upload the file to it via the BlobClient\n",
        "    if tempUrl != '':\n",
        "        client = BlobClient.from_blob_url(tempUrl)\n",
        "        with open(fileLocation, 'rb') as data:\n",
        "            client.upload_blob(data)\n",
        "        print(f\"{fileLocation} uploaded\")\n",
        "    else:\n",
        "        print(\"No sas url specified.\")\n",
        "\n",
        "    #Part 3:   Call the import API with the temp location as 'fileUrl' in the body of the API call\n",
        "    apiUrl = f\"https://api.powerbi.com/v1.0/myorg/groups/{workspaceId}/imports?datasetDisplayName={displayName}&nameConflict=Ignore&skipReport=false&overrideReportLabel=true&overrideModelLabel=true\"\n",
        "\n",
        "    body = {\n",
        "        \"fileUrl\": tempUrl\n",
        "    }\n",
        "\n",
        "    apiResponse = requests.post(\n",
        "        url=apiUrl,\n",
        "        headers=headers,\n",
        "        data=json.dumps(body)\n",
        "    )\n",
        "\n",
        "    if apiResponse.status_code != 200:\n",
        "        description = f'Error importing file:\\n  -Status Code:\\t{apiResponse.status_code}\\n  -Reason:\\t{apiResponse.reason}\\n  -RequestId:\\t{apiResponse.headers.get(\"RequestId\")}\\n  -Text:\\t{apiResponse.text}'\n",
        "        print(description)\n",
        "    else:\n",
        "        apiResponse = json.loads(apiResponse.text)\n",
        "        print(json.dumps(apiResponse,indent=2))\n"
      ]
    }
  ],
  "metadata": {
    "kernel_info": {
      "name": "python310-sdkv2"
    },
    "kernelspec": {
      "display_name": "Python 3.10 - SDK v2",
      "language": "python",
      "name": "python310-sdkv2"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.11"
    },
    "microsoft": {
      "host": {
        "AzureML": {
          "notebookHasBeenCompleted": true
        }
      },
      "ms_spell_check": {
        "ms_spell_check_language": "en"
      }
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
